{
    "@context": "https://w3id.org/ro/crate/1.1/context",
    "@graph": [
        {
            "@id": "./",
            "@type": "Dataset",
            "creativeWorkStatus": "InProgress",
            "datePublished": "2025-11-13T21:07:55+00:00",
            "description": "# kentsislab/proteomegenerator3\n\n[![GitHub Actions CI Status](https://github.com/shahcompbio/proteomegenerator3/actions/workflows/ci.yml/badge.svg)](https://github.com/shahcompbio/proteomegenerator3/actions/workflows/ci.yml)\n[![GitHub Actions Linting Status](https://github.com/shahcompbio/proteomegenerator3/actions/workflows/linting.yml/badge.svg)](https://github.com/shahcompbio/proteomegenerator3/actions/workflows/linting.yml)[![Cite with Zenodo](http://img.shields.io/badge/DOI-10.5281/zenodo.XXXXXXX-1073c8?labelColor=000000)](https://doi.org/10.5281/zenodo.XXXXXXX)\n[![nf-test](https://img.shields.io/badge/unit_tests-nf--test-337ab7.svg)](https://www.nf-test.com)\n\n[![Nextflow](https://img.shields.io/badge/nextflow%20DSL2-%E2%89%A524.04.2-23aa62.svg)](https://www.nextflow.io/)\n[![run with docker](https://img.shields.io/badge/run%20with-docker-0db7ed?labelColor=000000&logo=docker)](https://www.docker.com/)\n[![run with singularity](https://img.shields.io/badge/run%20with-singularity-1d355c.svg?labelColor=000000)](https://sylabs.io/docs/)\n\n## Introduction\n\n**kentsislab/proteomegenerator3** is a bioinformatics pipeline that can be used to create sample-specific, proteogenomics search databases from long-read RNAseq data. It takes in a samplesheet and aligned long-read RNAseq data as input, performs guided, de novo transcript assembly, ORF prediction, and then produces a protein fasta file suitable for use with computational proteomics search platforms (e.g, Fragpipe, DIA-NN).\n\n<!-- TODO nf-core:\n   Complete this sentence with a 2-3 sentence summary of what types of data the pipeline ingests, a brief overview of the\n   major pipeline sections and the types of output it produces. You're giving an overview to someone new\n   to nf-core here, in 15-20 seconds. For an example, see https://github.com/nf-core/rnaseq/blob/master/README.md#introduction\n-->\n\n<!-- TODO nf-core: Include a figure that guides the user through the major workflow steps. Many nf-core\n     workflows use the \"tube map\" design for that. See https://nf-co.re/docs/contributing/design_guidelines#examples for examples.   -->\n<!-- TODO nf-core: Fill in short bullet-pointed list of the default steps in the pipeline -->\n\n1. Pre-processing of aligned reads to create transcript read classes with [bambu](https://github.com/GoekeLab/bambu) which can be re-used in future analyses. Optional filtering:\n   1. Filtering on MAPQ and read length with [samtools](https://www.htslib.org/)\n2. Transcript assembly, quantification, and filtering with [bambu](https://github.com/GoekeLab/bambu). Option to merge multiple samples into a unified transcriptome.\n3. ORF prediction with [Transdecoder](https://github.com/TransDecoder/TransDecoder).\n4. Formatting of ORFs into a UniProt-style fasta file which can be used for computational proteomics searchs with [Fragpipe](https://fragpipe.nesvilab.org/), [DIA-NN](https://github.com/vdemichev/DiaNN), [Spectronaut](https://biognosys.com/software/spectronaut/).\n5. Concatenation of sample-specific proteome fasta produced in #4 with a UniProt proteome of the user's choice to allow for spectra to compete between non-canonical and canonical proteoforms.\n6. Deduplication of sequences and basic statistics with [seqkit](https://bioinf.shenwei.me/seqkit/usage/#quick-guide)\n7. MultiQC to collate package versions used ([`MultiQC`](http://multiqc.info/))\n\n## Usage\n\n> [!NOTE]\n> If you are new to Nextflow and nf-core, please refer to [this page](https://nf-co.re/docs/usage/installation) on how to set-up Nextflow. Make sure to [test your setup](https://nf-co.re/docs/usage/introduction#how-to-run-a-pipeline) with `-profile test` before running the workflow on actual data. When using the profile, it will run on a minimal test dataset that can be run in 5-10 minutes on most modern laptops.\n\nFirst, prepare a samplesheet with your input data that looks as follows:\n\n`samplesheet.csv`:\n\n```csv\nsample,bam,rcFile,fusion_tsv\nCONTROL_REP1,AEG588A1_S1_L002_R1_001.bam,,fusion_predictions.tsv\n```\n\nEach row represents a long-read RNAseq sample. The columns are as follows:\n\n1. `sample`: Sample name (required)\n2. `bam`: Aligned, sorted long-read RNAseq BAM file (required)\n3. `rcFile`: Optional Bambu read class file (.rds) from previous runs; use with `--skip_preprocessing` flag to speed up runtime and re-analyze previous samples\n4. `fusion_tsv`: Optional fusion predictions TSV file from ctat-lr-fusion\n\nTo produce the necessary files, we recommend using the [nf-core/nanoseq](https://nf-co.re/nanoseq/3.1.0/) pipeline for alignment, or [ctat-lr-fusion](https://github.com/TrinityCTAT/CTAT-LR-fusion) for fusion calling.\n\nNow, you can run the pipeline using:\n\n<!-- TODO nf-core: update the following command to include all required parameters for a minimal example -->\n\n```bash\nnextflow run kentsislab/proteomegenerator3 -r 1.1.0 \\\n   -profile <docker/singularity/.../institute> \\\n   --input samplesheet.csv \\\n   --fasta <REF_GENOME> \\\n   --gtf <REF_GTF> \\\n   --outdir <OUTDIR>\n```\n\nWhere `REF_GENOME` and `REF_GTF` are the reference genome and transcriptome respectively. These can be from GENCODE or Ensembl, but should match the reference used to align the data.\n\n> [!WARNING]\n> Please provide pipeline parameters via the CLI or Nextflow `-params-file` option. Custom config files including those provided by the `-c` Nextflow option can be used to provide any configuration _**except for parameters**_; see [docs](https://nf-co.re/docs/usage/getting_started/configuration#custom-configuration-files).\n\n### Additional parameters\n\nTo see all optional parameters that could be used with the pipeline and their explanations, use the help menu:\n\n```bash\nnextflow run kentsislab/proteomegenerator3 -r 1.1.0 --help\n```\n\nThis options can be run using flags. For example:\n\n```bash\nnextflow run kentsislab/proteomegenerator3 -r 1.1.0 \\\n   -profile <docker/singularity/.../institute> \\\n   --input samplesheet.csv \\\n   --fasta <REF_GENOME> \\\n   --gtf <REF_GTF> \\\n   --outdir <OUTDIR> \\\n   --filter_reads\n```\n\nWill pre-filter the bam file before transcript assembly is performed on mapq and read length.\n\nAs another example, you can skip multi-sample transcript merging and process each sample independently:\n\n```bash\nnextflow run kentsislab/proteomegenerator3 -r 1.1.0 \\\n   -profile <docker/singularity/.../institute> \\\n   --input samplesheet.csv \\\n   --fasta <REF_GENOME> \\\n   --gtf <REF_GTF> \\\n   --outdir <OUTDIR> \\\n   --skip_multisample\n```\n\nTo run with the latest version, which may not be stable you can use the `-r dev -latest` flags:\n\n```bash\nnextflow run kentsislab/proteomegenerator3 -r dev -latest --help\n```\n\nI have highlighted the following options here:\n\n1. `filter_reads`: use this flag to pre-filter reads using mapq and read length\n2. `mapq`: min mapq for read filtering [default: 20]\n3. `read_len`: min read length for read filtering [default: 500]\n4. `filter_acc_reads`: filter reads on accessory chromosomes; sometimes causes issues for bambu\n5. `skip_preprocessing`: use previously generated bambu read classes\n6. `NDR`: modulate bambu's novel discovery rate [default: 0.1]\n7. `recommended_NDR`: run bambu with recommended NDR (as determined by bambu's algorithm)\n8. `skip_multisample`: skip multi-sample transcript merging and process samples individually\n9. `single_best_only`: select only the single best ORF per transcript [default: false]\n10. `uniprot_proteome`: local path to UniProt proteome for (i) BLAST-based ORF validation in Transdecoder subworkflow and (ii) concatenation of the final proteome fasta file.\n11. `UPID`: UniProt proteome ID (UPID) for automated download (if no local path was provided with option #10) [default: UP000005640]\n\n## Credits\n\nkentsislab/proteomegenerator3 was originally written by Asher Preska Steinberg.\n\nWe thank the following people for their extensive assistance in the development of this pipeline:\n\n<!-- TODO nf-core: If applicable, make list of people who have also contributed -->\n\n## Contributions and Support\n\nIf you would like to contribute to this pipeline, please see the [contributing guidelines](.github/CONTRIBUTING.md).\n\n## Citations\n\n<!-- TODO nf-core: Add citation for pipeline after first release. Uncomment lines below and update Zenodo doi and badge at the top of this file. -->\n<!-- If you use kentsislab/proteomegenerator3 for your analysis, please cite it using the following doi: [10.5281/zenodo.XXXXXX](https://doi.org/10.5281/zenodo.XXXXXX) -->\n\n<!-- TODO nf-core: Add bibliography of tools and data used in your pipeline -->\n\nIf you use kentsislab/proteomegenerator3 for your analysis, please cite our manuscript:\n\n> **End-to-end proteogenomics for discovery of cryptic and non-canonical cancer proteoforms using long-read transcriptomics and multi-dimensional proteomics**\n>\n> Katarzyna Kulej, Asher Preska Steinberg, Jinxin Zhang, Gabriella Casalena, Eli Havasov, Sohrab P. Shah, Andrew McPherson, Alex Kentsis.\n>\n> _BioRXiv._ 2025 Aug 28. doi: [10.1101/2025.08.23.671943](https://doi.org/10.1101/2025.08.23.671943).\n\nAn extensive list of references for the tools used by the pipeline can be found in the [`CITATIONS.md`](CITATIONS.md) file.\n\nThis pipeline uses code and infrastructure developed and maintained by the [nf-core](https://nf-co.re) community, reused here under the [MIT license](https://github.com/nf-core/tools/blob/main/LICENSE).\n\n> **The nf-core framework for community-curated bioinformatics pipelines.**\n>\n> Philip Ewels, Alexander Peltzer, Sven Fillinger, Harshil Patel, Johannes Alneberg, Andreas Wilm, Maxime Ulysse Garcia, Paolo Di Tommaso & Sven Nahnsen.\n>\n> _Nat Biotechnol._ 2020 Feb 13. doi: [10.1038/s41587-020-0439-x](https://dx.doi.org/10.1038/s41587-020-0439-x).\n",
            "hasPart": [
                {
                    "@id": "main.nf"
                },
                {
                    "@id": "assets/"
                },
                {
                    "@id": "bin/"
                },
                {
                    "@id": "conf/"
                },
                {
                    "@id": "docs/"
                },
                {
                    "@id": "modules/"
                },
                {
                    "@id": "modules/local/"
                },
                {
                    "@id": "modules/nf-core/"
                },
                {
                    "@id": "workflows/"
                },
                {
                    "@id": "subworkflows/"
                },
                {
                    "@id": "nextflow.config"
                },
                {
                    "@id": "README.md"
                },
                {
                    "@id": "nextflow_schema.json"
                },
                {
                    "@id": "CHANGELOG.md"
                },
                {
                    "@id": "LICENSE"
                },
                {
                    "@id": "CITATIONS.md"
                },
                {
                    "@id": "modules.json"
                },
                {
                    "@id": "docs/usage.md"
                },
                {
                    "@id": "docs/output.md"
                },
                {
                    "@id": ".nf-core.yml"
                },
                {
                    "@id": ".pre-commit-config.yaml"
                },
                {
                    "@id": ".prettierignore"
                }
            ],
            "isBasedOn": "https://github.com/kentsislab/proteomegenerator3",
            "license": "MIT",
            "mainEntity": {
                "@id": "main.nf"
            },
            "name": "kentsislab/proteomegenerator3"
        },
        {
            "@id": "ro-crate-metadata.json",
            "@type": "CreativeWork",
            "about": {
                "@id": "./"
            },
            "conformsTo": [
                {
                    "@id": "https://w3id.org/ro/crate/1.1"
                },
                {
                    "@id": "https://w3id.org/workflowhub/workflow-ro-crate/1.0"
                }
            ]
        },
        {
            "@id": "main.nf",
            "@type": [
                "File",
                "SoftwareSourceCode",
                "ComputationalWorkflow"
            ],
            "dateCreated": "",
            "dateModified": "2025-11-13T16:07:55Z",
            "dct:conformsTo": "https://bioschemas.org/profiles/ComputationalWorkflow/1.0-RELEASE/",
            "keywords": [
                "nf-core",
                "nextflow"
            ],
            "license": [
                "MIT"
            ],
            "name": [
                "kentsislab/proteomegenerator3"
            ],
            "programmingLanguage": {
                "@id": "https://w3id.org/workflowhub/workflow-ro-crate#nextflow"
            },
            "sdPublisher": {
                "@id": "https://nf-co.re/"
            },
            "url": [
                "https://github.com/kentsislab/proteomegenerator3",
                "https://nf-co.re/kentsislab/proteomegenerator3/dev/"
            ],
            "version": [
                "1.1.1dev"
            ]
        },
        {
            "@id": "https://w3id.org/workflowhub/workflow-ro-crate#nextflow",
            "@type": "ComputerLanguage",
            "identifier": {
                "@id": "https://www.nextflow.io/"
            },
            "name": "Nextflow",
            "url": {
                "@id": "https://www.nextflow.io/"
            },
            "version": "!>=24.04.2"
        },
        {
            "@id": "assets/",
            "@type": "Dataset",
            "description": "Additional files"
        },
        {
            "@id": "bin/",
            "@type": "Dataset",
            "description": "Scripts that must be callable from a pipeline process"
        },
        {
            "@id": "conf/",
            "@type": "Dataset",
            "description": "Configuration files"
        },
        {
            "@id": "docs/",
            "@type": "Dataset",
            "description": "Markdown files for documenting the pipeline"
        },
        {
            "@id": "modules/",
            "@type": "Dataset",
            "description": "Modules used by the pipeline"
        },
        {
            "@id": "modules/local/",
            "@type": "Dataset",
            "description": "Pipeline-specific modules"
        },
        {
            "@id": "modules/nf-core/",
            "@type": "Dataset",
            "description": "nf-core modules"
        },
        {
            "@id": "workflows/",
            "@type": "Dataset",
            "description": "Main pipeline workflows to be executed in main.nf"
        },
        {
            "@id": "subworkflows/",
            "@type": "Dataset",
            "description": "Smaller subworkflows"
        },
        {
            "@id": "nextflow.config",
            "@type": "File",
            "description": "Main Nextflow configuration file"
        },
        {
            "@id": "README.md",
            "@type": "File",
            "description": "Basic pipeline usage information"
        },
        {
            "@id": "nextflow_schema.json",
            "@type": "File",
            "description": "JSON schema for pipeline parameter specification"
        },
        {
            "@id": "CHANGELOG.md",
            "@type": "File",
            "description": "Information on changes made to the pipeline"
        },
        {
            "@id": "LICENSE",
            "@type": "File",
            "description": "The license - should be MIT"
        },
        {
            "@id": "CITATIONS.md",
            "@type": "File",
            "description": "Citations needed when using the pipeline"
        },
        {
            "@id": "modules.json",
            "@type": "File",
            "description": "Version information for modules from nf-core/modules"
        },
        {
            "@id": "docs/usage.md",
            "@type": "File",
            "description": "Usage documentation"
        },
        {
            "@id": "docs/output.md",
            "@type": "File",
            "description": "Output documentation"
        },
        {
            "@id": ".nf-core.yml",
            "@type": "File",
            "description": "nf-core configuration file, configuring template features and linting rules"
        },
        {
            "@id": ".pre-commit-config.yaml",
            "@type": "File",
            "description": "Configuration file for pre-commit hooks"
        },
        {
            "@id": ".prettierignore",
            "@type": "File",
            "description": "Ignore file for prettier"
        },
        {
            "@id": "https://nf-co.re/",
            "@type": "Organization",
            "name": "nf-core",
            "url": "https://nf-co.re/"
        }
    ]
}